{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dca94ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. Data Simulation and Input Preparation ---\n",
    "print(\"Step 1: Simulating data...\")\n",
    "\n",
    "# Dimensions\n",
    "n_xenium_cells = 1000\n",
    "n_visium_spots = 100\n",
    "n_xenium_genes = 250\n",
    "n_visium_genes = 500\n",
    "\n",
    "# Create mock expression matrices\n",
    "xenium_expression = np.random.rand(n_xenium_cells, n_xenium_genes).astype(np.float32)\n",
    "visium_expression = np.random.rand(n_visium_spots, n_visium_genes).astype(np.float32)\n",
    "\n",
    "# Create the mapping matrix\n",
    "mapping_matrix = np.zeros((n_xenium_cells, n_visium_spots), dtype=np.float32)\n",
    "for i in range(n_xenium_cells):\n",
    "    mapping_matrix[i, np.random.randint(0, n_visium_spots)] = 1\n",
    "\n",
    "# Convert numpy arrays to PyTorch Tensors\n",
    "x_tensor = torch.from_numpy(xenium_expression)\n",
    "v_tensor = torch.from_numpy(visium_expression)\n",
    "map_tensor = torch.from_numpy(mapping_matrix)\n",
    "\n",
    "# Prepare the Visium context for each cell (this remains necessary)\n",
    "v_mapped_to_cells = torch.matmul(map_tensor, v_tensor)\n",
    "\n",
    "print(f\"Xenium input shape: {x_tensor.shape}\")\n",
    "print(f\"Visium context input shape: {v_mapped_to_cells.shape}\\n\")\n",
    "\n",
    "\n",
    "# --- 2. PyTorch Model Definition (Dual-Input \"Two-Tower\" Architecture) ---\n",
    "\n",
    "class DualInputModel(nn.Module):\n",
    "    def __init__(self, n_xenium_genes, n_visium_genes):\n",
    "        super(DualInputModel, self).__init__()\n",
    "\n",
    "        # --- Tower 1: Xenium Feature Extractor ---\n",
    "        self.xenium_tower = nn.Sequential(\n",
    "            nn.Linear(n_xenium_genes, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64) # Output is a 64-dim feature vector\n",
    "        )\n",
    "\n",
    "        # --- Tower 2: Visium Feature Extractor ---\n",
    "        self.visium_tower = nn.Sequential(\n",
    "            nn.Linear(n_visium_genes, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128) # Output is a 128-dim feature vector\n",
    "        )\n",
    "\n",
    "        # --- Shared Decoder: Merges features and generates U ---\n",
    "        # Input dimension is the sum of the tower outputs (64 + 128 = 192)\n",
    "        merged_dim = 64 + 128\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(merged_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, n_visium_genes) # Final output is a row of U\n",
    "        )\n",
    "\n",
    "        # --- Trivial Projector for Xenium Reconstruction ---\n",
    "        self.xenium_projector = nn.Linear(n_visium_genes, n_xenium_genes)\n",
    "\n",
    "\n",
    "    def forward(self, x_input, v_context_input, mapping_matrix):\n",
    "        # 1. Process inputs through their respective towers\n",
    "        x_features = self.xenium_tower(x_input)\n",
    "        v_features = self.visium_tower(v_context_input)\n",
    "\n",
    "        # 2. Merge the features from both towers\n",
    "        merged_features = torch.cat([x_features, v_features], dim=1)\n",
    "\n",
    "        # 3. Generate the U matrix using the shared decoder\n",
    "        U_predicted = self.decoder(merged_features)\n",
    "\n",
    "        # 4. Reconstruct Xenium by projecting U\n",
    "        x_recon = self.xenium_projector(U_predicted)\n",
    "\n",
    "        # 5. Reconstruct Visium by aggregating U\n",
    "        map_T = mapping_matrix.T\n",
    "        v_aggregated = torch.matmul(map_T, U_predicted)\n",
    "        cells_per_spot = map_T.sum(dim=1, keepdim=True).clamp(min=1e-6)\n",
    "        v_recon = v_aggregated / cells_per_spot\n",
    "\n",
    "        return x_recon, v_recon, U_predicted\n",
    "\n",
    "# --- 3. Training Setup ---\n",
    "\n",
    "print(\"Step 2: Initializing Dual-Input model, loss, and optimizer...\")\n",
    "model = DualInputModel(\n",
    "    n_xenium_genes=n_xenium_genes,\n",
    "    n_visium_genes=n_visium_genes\n",
    ")\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "num_epochs = 100\n",
    "\n",
    "print(\"Model architecture:\")\n",
    "print(model)\n",
    "print(\"\\nStarting training...\\n\")\n",
    "\n",
    "# --- 4. The Training Loop ---\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "\n",
    "    # Forward pass with two separate inputs\n",
    "    x_recon, v_recon, _ = model(x_tensor, v_mapped_to_cells, map_tensor)\n",
    "\n",
    "    # Calculate Losses\n",
    "    loss_x = loss_fn(x_recon, x_tensor)\n",
    "    loss_v = loss_fn(v_recon, v_tensor)\n",
    "    total_loss = loss_x + loss_v # Simple sum, can be weighted if needed\n",
    "\n",
    "    # Backpropagation\n",
    "    optimizer.zero_grad()\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(\n",
    "            f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "            f'Total Loss: {total_loss.item():.4f}, '\n",
    "            f'X-Recon: {loss_x.item():.4f}, '\n",
    "            f'V-Recon: {loss_v.item():.4f}'\n",
    "        )\n",
    "\n",
    "# --- 5. Generating the Final Universal Matrix ---\n",
    "print(\"\\n--- 5. Generating the Final Universal Matrix ---\")\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Run the model one last time to get the final generated U\n",
    "    _, _, universal_matrix_tensor = model(x_tensor, v_mapped_to_cells, map_tensor)\n",
    "\n",
    "universal_matrix_numpy = universal_matrix_tensor.cpu().numpy()\n",
    "\n",
    "print(\"Universal Matrix generation complete.\")\n",
    "print(f\"Shape of the final matrix: {universal_matrix_numpy.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cdc2c6",
   "metadata": {},
   "source": [
    "Of course. You've perfectly described the most elegant and powerful architecture. We will discard the \"patchwork\" idea and build a model that takes Xenium and Visium data as two separate, direct inputs, learns from them independently, and then merges them to generate the final U matrix.\n",
    "\n",
    "This is a classic \"multi-modal\" or \"two-tower\" network design.\n",
    "\n",
    "The Dual-Input Architecture\n",
    "Here's how this superior model will work:\n",
    "\n",
    "Two Input Towers: The model will have two distinct input pathways or \"towers\":\n",
    "\n",
    "Xenium Tower: A dedicated neural network that processes only the Xenium data (X). Its job is to learn a rich, internal representation of the cell-specific information.\n",
    "\n",
    "Visium Tower: A second, parallel neural network that processes only the contextual Visium data (V). Its job is to learn a representation of the cell's neighborhood.\n",
    "\n",
    "Merge Layer: The outputs from both towers are then brought together and concatenated into a single, powerful feature vector. This vector now contains processed, high-level features from both modalities.\n",
    "\n",
    "Shared Decoder: This merged vector is fed into a final, deep neural network. This decoder's job is to take the combined high-level features and generate the final, harmonized row of the U matrix.\n",
    "\n",
    "Trivial Reconstruction & Loss: The rest of the process remains the same. The generated U matrix is used to reconstruct X' and V', and the loss is calculated by comparing them to the originals. The error is then backpropagated through the entire system, training all three components (both towers and the decoder) simultaneously.\n",
    "\n",
    "This architecture is superior because it allows the model to create specialized representations for each data type before forcing them to interact. It's a much cleaner and more effective way to learn the connections.\n",
    "\n",
    "I will now update the code to implement this final, dual-input architecture."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
